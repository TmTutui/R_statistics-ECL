---
title: "BE1- plans d'expériences et régression logistique"
author: "Tulio NAVARRO TUTUI, Filipe PENNA CERAVOLO SOARES"
course: "Statistique appliquée aux sciences de l'ingénieur"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
  pdf_document: default
---

<!-- 
    For reference:
    - http://rmarkdown.rstudio.com>
    - https://lms.fun-mooc.fr/c4x/UPSUD/42001S02/asset/RMarkdown.html
 -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 6, fig.height = 6)
```

# Exercice 01 - Plan d'expériences - Criblage

## 1. Étude du plan

Selon l'ennonce, chaque experiment est fait 4 fois.
Donc on a 16 experiences differénts.
À partir de la lecture de le fichier, on réalise que on a un plan 
fractionnaire, avec $n = 2^{6-2} = 2^{4} = 16$.

En étudiant les 16 premières lignes, on note que : (A.B.C = E) et (A.C.D = F).
Autrement dit, Ctemp est une interaction triple de Ltemp, Ltime et Lpress , et
Catmos est une interaction triple de Ltemp, Lpress, Ctemp. De ce fait, les effets
principaux se confondent tous avec des interactions triples. Or, comme dans le
cours, on fait l'hypothèse que les interactions triples sont d'influence
inenvisageable et donc négligeables. De ce fait, les effets principaux
peuvent être estimés sans confusion. Cependant, ce n'est pas le cas
des effets des interactions doubles.

```{r}
silicium = read.table(file = "./02. Segundo BE/01. Treinamento/silicium.txt", 
                              header = TRUE)
head(silicium)
p = length(silicium) - 1
n = nrow(silicium)
x = as.matrix(silicium[,-7])
nombre = t(x)%*%x
```

## 2. Ajuster un modèle linéaire de la variable Camber en fonction des 6 facteurs. Analyser la sortie summary du modèle

## 3. Retrouver par le calcul le chiffre de la colonne Std Error

En analysant le summary du modèle, on observe que les paramètres 
Ltemp, Lpress, Ctime et Catoms sont des paramètres explicatifs du modèle. Par contre,
Ltime et Ctemp n'en sont pas. 

```{r} 
mod1 = lm(Camber~., data = silicium)
summary(mod1)
anova(mod1)

```

Du summury, on obtient que $\sigma = 38.34$. Donc

```{r} 
library(matlib)
std_error = (38.34*sqrt((inv(nombre))))[1,1]

```

## 4. Estimer un modèle plus simple ne comprenant que les facteurs influents. Comparer l'estimation des coefficients avec le modèle précédent

```{r} 
silicium_adj = lm(Camber ~ Ltemp + Lpress + Ctime + Catmos, data = silicium)
summary(silicium_adj)
```

Les quatre coefficients obtenus avec ce modèle sont strictement similaires aux
quatre coefficients associées aux mêmes variables explicatives (identifiés en
jaune précédemment) dans le modèle précédent qui prenait en compte les six
variables explicatives. De ce fait, en supprimant deux variables
explicatives, aucun potentiel effet d'interaction n'a été perdu. Ceci
valide la suppression des deux variables Ltime et Ctemp.

## 5. 

### 5.1. Quelles sont les conditions expérimentales qui permettent de minimiser la courbure Camber ?

Pour minimiser la courbure de la plaque de silicium dans notre modèle, on veut
d'une part maximiser l'influence des facteurs à influence négative sur la
courbure, et d'autre part minimiser l'influence des facteurs à influence positive
sur la courbure. Ainsi, on va se placer en 1 pour Ctime et Catmos et en -1 pour
Ltemp et Lpress. Autrement dit, les conditions expérimentales pour
minimiser la courbure sont : Ctime 29 secondes ; Catmos 26°C ;
Ltemp 55 °C et Lpress 5bars. 

### 5.2. Donner un intervalle de confiance pour la courbure moyenne en ce point de fonctionnement optimal

On cherche maintenant un intervalle de confiance pour la courbure moyenne en
ce point de fonctionnement optimal.

```{r} 
frame = data.frame(Ltemp = -1, Lpress = -1, Ctime = 1, Catmos = 1)
base_prediction = data.frame(predict(silicium_adj, frame, interval="confidence", level=0.95))
upper_limit = 25 + 2*38.53/sqrt(64)
```

Avec les conditions initiales évoquées précédemment, R situe Camber entre la
lower value de -17,97 et la upper value de 25,12. En valeur absolue (cambrure
toujours positive) et en arrondissant on obtient un intervalle [0 ; 25,2]. 

On souhaite que cet intervalle soit un intervalle de confiance à 95 %. 
Connaissant la forme [x̅− 2σ(X)/√nn ; x̅+2σ(X)/√nn] de l'intervalle,et l'erreur
standard dans notre modèle qui vaut 38,53, notre intervalle de confiance à
95 % sera : Camber Є [0 ; 102,06]

On étudie enfin l'influence dans notre modèle d'une augmentation de 5°C de la
température de laminage de la plaque (soit +0,5 en valeurs normalisées par
rapport à l'intervalle [55°C;75°C] ).

### 5.3. Quel est l'impact sur la courbure d'une augmentation de 5 degrés C de la température de laminage ?

On étudie enfin l'influence dans notre modèle d'une augmentation de 5°C de la
température de laminage de la plaque (soit +0,5 en valeurs normalisées par
rapport à l'intervalle [55°C;75°C] ). 

```{r} 
frame_augment = data.frame(Ltemp = -0.5, Lpress = -1, Ctime = 1, Catmos = 1)
adj_prediction = data.frame(predict(silicium_adj, frame_augment, interval="confidence", level=0.95))
dif = adj_prediction$fit - base_prediction$fit
```

Précédemment on avait en les points minimum une courbure attendue de 3,57.
Ici, après une augmentation de 5°C on obtient une courbure de 13,30. Ainsi,
une telle augmentation de la température de laminage aboutit à une
augmentation de 9,73 de la courbure. 

### 6. Les hypothèses du modèle sont-elles vérifiées ? expliquer

L'hypothèse d'une dépendance uniquement linéaire en les quatre variables
explicatives Ltemp, Lpress, Ctime et Catmos n'est pas parfaitement vérifiée. En
effet, le modèle de régression obtenu a un coefficient de régression R2=0,6839
assez faible. 

De plus, on plot la régression linéaire comme montré en haut de page suivante.
Les résidus ne sont pas uniformément répartis, ce qui confirme l'existence de
dépendances qui restent à expliquer.

```{r} 
plot(silicium_adj)
```

# Exercice 01 -  Régression logistique

## 1. Décrire les variables

Le fichier neuralgia.txt décrit un ensemble de 60 patients soignés pour névralgie
avec chacun quatre variables explicatives : l'âge (variabe à modalités
mutliples), le sexe, (variable à deux modalités) le traitement suivi (variable à
trois modalités) et la durée (variable à modalités multiples). La variable étudiée
est Pain et représente la souffrance du patient : 0 s'il ne souffre pas et 1 s'il
souffre. On visualise les premières lignes de ce fichier importé dans R ci-dessous

```{r}
neuralgia = read.table(file = "./02. Segundo BE/01. Treinamento/neuralgia.txt", 
                              header = TRUE)
head(neuralgia)
unique(neuralgia$Treatment)
unique(neuralgia$Sex)
```

## 2. Partager le fichier en un fichier d'apprentissage (80%) et un fichier de test (20%)

```{r}
n = nrow(neuralgia)
p = n * 0.8
u = sample(1:n,p)
donnes_apprentissage = neuralgia[u,]
donnes_test = neuralgia[-u,]
nrow(donnes_apprentissage)
nrow(donnes_test)
```

## 3. Réaliser sur le fichier d'apprentissage une régression logistique pour prédire la variable Pain

L'évènement modélisé ici est l'évènement « il y a Pain ». Soit π(x) la probabilité de l’évènement que 
l'on cherche à modéliser. Alors le modèle logit consiste à écrire que :

Où sont les paramètres à estimer. La fonction Logit est la fonction définie par :

```{r}
donnes_apprentissage$Treatment = as.factor(donnes_apprentissage$Treatment)
donnes_apprentissage$Sex = as.factor(donnes_apprentissage$Sex)
logistic_model = glm(Pain ~ Treatment + Sex + Age + Duration, family=binomial(link="logit"), data=donnes_apprentissage)
```

## 4. Analyser le résultat des commandes Anova

```{r}
anova(logistic_model,test="Chisq") # test du Chi carré
anova(logistic_model,test.statistic = "LR", type= 'III') # test de maximum de vraisemblance
anova(logistic_model,test.statistic = "Wald", type= 'III') # test de Wald-Wolfowitz
```

Avec le test du Chi carré, la durée du traitement n'a aucune influence sur la
douleur du patient. Le traitement employé, le sexe et l'âge du patient ont eux
une influence. 

Dans le test de maximum de vraisemblance, la durée du traitement n'a toujours pas d'influence 
et le traitement 
employé, l'âge et le sexe du patient ont une influence. Notons néanmoins que
l'influence estimée de ces trois variables explicatives est différente du test
précédent. Ici, le type de traitement appliqué a une plus forte influence ainsi
que l'âge, le sexe ayant une influence du même ordre de grandeur. 

Pour le Wald-Wolfwitz, la même conclusion sur la non influence de la durée du traitement. 
De la même manière, les influences estimées du type de traitement, de l'âge et du
sexe du patient sont différentes des analyses précédentes.

```{r}
summary(glm(Pain ~.,family=binomial(link="logit"),data=donnes_apprentissage))
```

A la lecture de ce summary, on conclut encore une fois sur la large non-influence (en rouge) de la durée du traitement sur la douleur ressentie par le 
patient. 
Le sexe et l'âge du patient sont tout deux influents. Concernant le traitement, 
on peut préciser à la lecture du summary que le traitement B n'a aucune 
influence sur Pain alors que le traitement P en a une grande (en vert). 

## 5. Réaliser maintenant une procédure forward pour le critère AIC

On effectue maintenant une procédure forward pour construire le modèle
basé sur les variables les plus significatives. Celui ci fonctionne en
ajoutant à chaque itération une variable au modèle. La variable ajoutée sera
celle qui minimisera le critère AIC. On arrête les itérations quand toutes les
variables auront été ajoutées ou bien quand toutes les variables restantes à
ajouter dépassent un certain seuil (5%) du critère.
Dans notre cas, on obtient les itérations et le résultat (en vert) affichés ci
dessous :

```{r}
logistic_model_2=glm(Pain ~ 1,family=binomial,data=donnes_apprentissage)
next_step <- step(logistic_model_2, direction="forward", scope=list(upper=~(Treatment + Sex + Age + Duration)), trace = TRUE)
next_step$anova
anova(forward,test.statistic="LR",type = 'III')
```

Le modèle obtenu par cette procédure confirme les analyses faites
précédemment. Il sélectionne les variables explicatives Traitement, Age et Sex
avec Traitement qui a la plus grande influence car sélectionné en premier.

## 6. A l'aide du fichier test, comparer les matrices de confusions pour les deux modèles

```{r}
logistic_model_reduit = glm(Pain ~ Treatment + Sex + Age, family=binomial(link="logit"), data=donnes_apprentissage)
predict = exp(predict(logistic_model, newdata = donnes_test))/(1+exp(predict(logistic_model, newdata=donnes_test)))
predict_reduit = exp(predict(logistic_model_reduit, newdata =donnes_test))/(1+exp(predict(logistic_model_reduit, newdata =donnes_test)))
table(predict > 0.5, donnes_test$Pain)
table(predict_reduit > 0.5, donnes_test$Pain)
```

Même résultat !!

## 7. On se fixe un modèle. Etudier la sensibilité des qualités prédictives à l'échantillon 

```{r}
calculer_diff_vector <- function(n,p,neuralgia){

  diff = vector("numeric",50)

  for (i in 1:50) {
    u = sample(1:n,p)
    donnes_apprentissage = neuralgia[u,]
    donnes_test = neuralgia[-u,]
    donnes_apprentissage$Treatment = as.factor(donnes_apprentissage$Treatment)
    donnes_apprentissage$Sex = as.factor(donnes_apprentissage$Sex)
    logistic_model = glm(Pain ~ Treatment + Sex + Age + Duration, family=binomial(link="logit"), data=donnes_apprentissage)
    predict = exp(predict(logistic_model, newdata = donnes_test))/(1+exp(predict(logistic_model, newdata=donnes_test)))
    results = table(predict > 0.5, donnes_test$Pain)
    diff[i] = (results[1,1]+results[2,2])/12
  }

  return (diff)

}

base_case = calculer_diff_vector(n,n * 0.8,neuralgia)
alt_case_1 = calculer_diff_vector(n,n * 0.9,neuralgia)
alt_case_2 = calculer_diff_vector(n,n * 0.7,neuralgia)
alt_case_3 = calculer_diff_vector(n,n * 0.6,neuralgia)

aver = c(mean(base_case), mean(alt_case_1), mean(alt_case_2), mean(alt_case_3))
plot(aver, ylim=0:1)
```

