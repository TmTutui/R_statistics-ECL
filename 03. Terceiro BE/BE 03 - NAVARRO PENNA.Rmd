---
title: "BE3 - apprentissage statitique"
author: "Tulio NAVARRO TUTUI, Filipe PENNA CERAVOLO SOARES"
course: "Statistique appliquée aux sciences de l'ingénieur"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
  html_document: default
---

<!-- 
    For reference:
    - http://rmarkdown.rstudio.com>
    - https://lms.fun-mooc.fr/c4x/UPSUD/42001S02/asset/RMarkdown.html
 -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Exercice 1 : Bitume - approches PLS, PCR , Lasso

## 1. Lire les données «bitume.train.txt» et «bitume.test.txt».

```{r}
library(DiceEval)
library(car)
library(MASS)

bitume_train = read.table("bitume.train.txt", header = T)
bitume_test  = read.table("bitume.test.txt", header = T)

p = ncol(bitume_train)

```

## 2. Visualiser sur le même graphes avec des couleurs différentes les 35 spectres de l'échantillon d'apprentissage. Tracer l'histogramme des pénétrabilités correspondantes.

## 3. Faire de même avec l'échantillon test.

## BONUS Faire une classification pour identifier des typologies différentes de spectres (routines kmeans ou hclust). Tracer les pénétrabilités en fonction du numéro de classe. Y-a-t-il un lien ?

## 4. Ajuster un modèle PCR et PLS (fonction pcr et plsr du package pls) puis un modèle lasso. Expliquer les différentes étapes de la sélection des hyperparamètres des méthodes. Interpréter les modèles obtenus. Pour les modèles PCR et PLS on visualisera notamment les premières fonctions propres. Comparer la qualité prédictive sur l'ensemble test des modèles ainsi "calibrés".

#### PCR

```{r}
library(pls)
#PCR
bitume_pcr <- pcr(class ~., 60, data = bitume_train)
```

Faire le choix du nombre de composantes par validation croisée en utilisant la routine crossval.

```{r}
bitume_cv <- crossval(bitume_pcr, segments = 10)
plot(MSEP(bitume_cv))
```

```{r}
nbcomp = aaaaaaaaaaaa  # choose best value according to the plot
Y_PCR = predict(bitume_pcr, newdata = bitume_test, ncomp = nbcomp, type = "response") # nolint

RMSE_PCR = RMSE(bitume_test[, p], Y_PCR)
RMSE_PCR
```

#### PLS

```{r}
bitume_pls <- plsr(class ~., 60, data = bitume_train)
bitume_pls.cv <- crossval(bitume_pls, segments = 10)
plot(MSEP(bitume_pls.cv))
```

```{r}
Y_PLS = predict(bitume_pls, newdata = bitume_test, ncomp = nbcomp, type = "response")

RMSE_PLS = RMSE(bitume_test[, p], Y_PLS)
RMSE_PLS

```

#### Lasso
```{r}
#--------------------------------------------------------------
# lasso
#--------------------------------------------------------------

library(lars)
# y = as.matrix(bitume_train[, p])
# x = as.matrix(bitume_train[, -p])
# x_extend = x
# 
# # makes the binary combinations of all columns
# for (i in 1:(p - 2)) {
#   for (j in 2:(p - 1)) {
#     x_extend = cbind(x_extend, x[, i] * x[, j])
#   }
# }

mod_lasso = lars(bitume_train[, p], bitume_train[, -p], type = "lasso")

CV = cv.lars(x, y, K = 10, index=seq(from = 0, to = 1, length = 100),
             trace = FALSE, plot.it = TRUE, se = TRUE, type = "lasso", mode = "fraction")

```


```{r}

value = aaaaaaaaaaaa  # choose best value according to the plot

# newx = as.matrix(bitume_test[, -p])
# for (i in 1:(p - 2))
# {
#   for (j in 2:(p - 1))
#   {
#     newx = cbind(newx, newx[, i] * newx[, j])
#   }
# }

fits <- predict.lars(mod_lasso, bitume_test[, -p], s = value, mode = "frac")

RMSE_lasso = RMSE(bitume_test[, p], fits$fit)

```

## 5. Pour les 3 méthodes, représenter les pénétrabilités prédites en fonction des pénétrabilités observées sur les 2 ensembles : apprentissage et test.

## 6. Pourrait-on essayer d'ajuster un modèle linéaire ?

# Exercice 2 : Carseats

```{r}
carseat = read.table("carseat.txt", header = T)
summary(carseat)
dim(carseat)
```

## 1. Séparer les données en un ensemble d'apprentissage (70%) et un ensemble de test (30%).

```{r}
set.seed(23)
apprentissage_fraction = as.integer(nrow(carseat) * 0.7)
u = sample(1:nrow(carseat), apprentissage_fraction)
carseat.train = carseat[u,]
carseat.test = carseat[-u,]
```

## 2. Mettre en place un modèle CART, RF, bagging et boosting. Expliquer précisément les différentes étapes de la mise en oeuvre. Donner les avantages et les inconvénients de chacun de ces modèles. Illustrer cela sur les données à disposition.

### CART

```{r}
library(rpart)
cont = rpart.control(cp = 0.0001)  # define minimum cp
mod_tree <- rpart(class ~., data = carseat.train, control = cont)
par(mfrow = c(1, 1))
plot(mod_tree, uniform = TRUE, margin = 0.05)
text(mod_tree, cex = 0.6)
```

```{r}
library(DiceEval)
y_pred_tree <- predict(mod_tree_pruned, housing.test[, -p])
RMSE_cart = RMSE(housing.test[, p], y_pred_tree)
RMSE_cart
```

### Random forest

### bagging

### Boosting

## 3. Quelle est l'approche qui donne les meilleurs résultats sur l'ensemble test ?

## 4. Si on décide de mettre en place un modèle linéaire avec une sélection backward sur les tests d'influence des variables, comment faut-il procéder ?